{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF text extraction playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import re\n",
    "import glob\n",
    "import pprint\n",
    "from random import shuffle\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(['words', 'wordnet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting text into separate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DELIM = '_'\n",
    "files = glob.glob('files/pdf/*')\n",
    "\n",
    "for file in files:\n",
    "    with pdfplumber.open(file) as pdf:\n",
    "        \n",
    "        # extracting all text\n",
    "        text = ''\n",
    "        for page in pdf.pages:\n",
    "            try:\n",
    "                text += page.extract_text()\n",
    "            except TypeError:\n",
    "                continue\n",
    "\n",
    "        # extracting name\n",
    "        name = re.findall(r'A\\/RES\\/\\d{2}\\/\\d{1,3}', text)\n",
    "        name = list(set(name))\n",
    "        \n",
    "        if len(name) == 0:\n",
    "            continue\n",
    "        \n",
    "        if len(name) > 1:\n",
    "            print('[ACTION]: multiple res symbols:', name, 'choose index; file', file)\n",
    "            index = int(input('>>>'))\n",
    "            name = list(name[index])\n",
    "        \n",
    "        name = name[0].replace('/', DELIM)\n",
    "\n",
    "        # save file with text\n",
    "        with open('files/text/' + name + '.txt', 'w') as txt:\n",
    "            txt.write(text)\n",
    "        \n",
    "        print('[INFO]: saved file: ', name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting clauses\n",
    "\n",
    "For the cleanest clause extractions, some data sacrifices are to be made. The PDF documents, on each page, contain both headers and footers, which, when stitching the documents together, produces noise in the data. To increase the quality, we get rid of the last and first elements in the list of parsed clauses. Some other ideas:\n",
    "\n",
    "- remove \"Recalling\" and \"Reaffirming\" clauses due to high percentage of references that are deleted by the regex cleaners\n",
    "- trhere's still the problem of sub-clauses. Do they remain in the data? Potential removal: see if the clause contains letters a, b, c, d, e... in alphabetical order single space apart\n",
    "- some words are also strewn together. https://en.wikipedia.org/wiki/Longest_word_in_English states that on average the longest word found in a text is 20 characters. Anything above that can be removed for suspect being strewn together. Possibly use a dictionary? Consider existence in dictionary (can be indexed for fast search), and if it doesn't exist, the length of the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clauses starters, taken from https://www.un.org/en/model-united-nations/drafting-resolutions\n",
    "PREAMBS = [\n",
    "    'Reiterating', 'Recognizing', 'Highlighting', 'Acknowledging', 'Affirming', 'Appreciating', 'Approving', 'Aware', 'Bearing in mind', 'Believing', \n",
    "    'Convinced', 'Desiring', 'Disturbed', 'Emphasizing', 'Expecting', 'Expressing', 'Fully', 'Guided', 'Having', 'Mindful', 'Noting', 'Emphasising'\n",
    "    'Observing', 'Reaffirming', 'Realising', 'Realizing', 'Recalling', 'Recognising', 'Seeking', 'Underlining', 'Welcoming', 'Whereas',\n",
    "    'Deeply alarmed', 'Alarmed', 'Stressing', 'Taking', 'Deeply', 'Cognizant', 'Appreciative', 'Confident', 'Congratulating', 'Recognizing'\n",
    "    'Declaring', 'Deploring', 'Fulfilling', 'Keeping', 'Pointing', 'Referring', 'Reminding', 'Viewing', 'Commending', 'Concerned', 'Conscious', 'Considering'\n",
    "]\n",
    "OPERS = [\n",
    "    'Also requests', 'Welcomes', 'Accepts', 'Adopts', 'Agrees', 'Appeals', 'Approves', 'Authorizes', 'Commends', 'Condemns', 'Considers', 'Decides', 'Declares', 'Determines',\n",
    "    'Also decides', 'Directs', 'Emphasizes', 'Encourages', 'Endorses', 'Invites', 'Notes', 'Notes with approval', 'Notes with concern', 'Notes with satisfaction', 'Proclaims', 'Calls',\n",
    "    'Reaffirms', 'Recommends', 'Reminds', 'Repeals', 'Requests', 'Resolves', 'Suggests', 'Stresses', 'Supports', 'Takes note', 'Urges', 'Expresses', 'Further', 'Also', 'Acknowledges',\n",
    "    'Recognizes', 'Reiterates', 'Affirms', 'Asks', 'Authorises', 'Congratulates', 'Confirms', 'Deplores', 'Designates', 'Hopes', 'Proposes', 'Regrets', 'Seeks', 'Strongly', 'Trusts', 'Transmits'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(file):\n",
    "    \"\"\" Processing and regex for files in an async manner \"\"\"\n",
    "    results = list()\n",
    "\n",
    "    with pdfplumber.open(file) as pdf:\n",
    "\n",
    "        all_clauses = list()\n",
    "        all_text = str()\n",
    "\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "\n",
    "            if not text:\n",
    "                continue\n",
    "\n",
    "            all_text += text\n",
    "\n",
    "            # text cleaning\n",
    "            text = re.sub(' +', ' ', re.sub(r'\\t|\\n|\\r', ' ', text)).strip()  # cleaning multiple spaces and indentation chars\n",
    "            text = re.sub('(\\s+)', ' ', re.sub('[^a-z\\s]+', ' ', text, flags=re.IGNORECASE)).strip()  # removing everything not in the english alphabet\n",
    "\n",
    "            clauses = re.split(f\"({'|'.join(PREAMBS + OPERS)})\", text)  # split by preambular and operative clauses, keeping delimeter\n",
    "            clauses = [a + ' ' + b for a, b in zip(clauses[1::2],  clauses[::2])] # connecting split delimeters and their clauses\n",
    "            clauses = [re.sub(r'[A-Z]+[\\s]+', ' ', x) for x in clauses] # cleaning independent leftover debris characters\n",
    "            clauses = [re.sub(' +', ' ', x) for x in clauses]  # once more cleaning multiple spaces and indentation chars\n",
    "            clauses = [x for x in clauses if not bool(re.findall(r'\\w{20,}', x))]  # removes words 20 chars or more\n",
    "            clauses = [x for x in clauses if len(x.split()) > 10]  # any clauses with less than 10 words\n",
    "\n",
    "            all_clauses.extend(clauses[2:-1]) # removing the end and beginning elements because of headers & footers\n",
    "\n",
    "    # exit if no text extraction has been made\n",
    "    if not all_text:\n",
    "        return None\n",
    "\n",
    "    # extracting resolution name\n",
    "    names = re.findall(r'A\\/RES\\/\\d{2}\\/\\d{1,3}', all_text)\n",
    "    names = list(set(names))\n",
    "    name = str()\n",
    "\n",
    "    if len(names) == 1:\n",
    "        name = names[0]\n",
    "    # elif len(names) > 1 and len(all_clauses) > 0:\n",
    "    #     print('[ACTION]: multiple res symbols:', names, 'choose index; file', file)\n",
    "    #     index = int(input('>>> '))\n",
    "    #     name = names[index]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    # adding information for dataframe\n",
    "    for clause in all_clauses:\n",
    "        results.append([name, clause])\n",
    "\n",
    "    return results\n",
    "\n",
    "    # logging and such:\n",
    "    # print(f\"PROG: {i}/{len(files)} ({round(i / len(files) * 100, 2)}%); added {len(all_clauses)} clauses from {name} ({file}) to dataframe.\")\n",
    "    # counter += 1\n",
    "\n",
    "    # if counter % 20 == 0:\n",
    "    #     clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    files = glob.glob(\"files/pdf/*\"); shuffle(files);\n",
    "    all_data = list()\n",
    "    counter = 0\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=5) as executor:\n",
    "        bunch_of_futures = {executor.submit(process_files, file): file for file in files}\n",
    "\n",
    "        for i, future in enumerate(as_completed(bunch_of_futures)):\n",
    "            try:\n",
    "                data = future.result()\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "            if not data:\n",
    "                continue\n",
    "            else:\n",
    "                counter += 1\n",
    "\n",
    "            len_clauses = len(data)\n",
    "            name = data[0][0]\n",
    "            file = bunch_of_futures[future]\n",
    "            all_data.extend(data)\n",
    "\n",
    "            print(f\"PROG: {i}/{len(files)} ({round(i / len(files) * 100, 2)}%); added {len_clauses} clauses from {name} ({file}) to dataframe.\")\n",
    "\n",
    "            if counter % 20 == 0:\n",
    "                clear_output(wait=True)\n",
    "                print(f\"CURRENT PROGRESS: {round(i / len(files) * 100, 2)}\\n\")\n",
    "\n",
    "    df = pd.DataFrame(all_data, columns=['resolution', 'clause'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
